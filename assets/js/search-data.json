{
  
    
        "post0": {
            "title": "Logistic Regression implementation",
            "content": "Overview . Given the problem . A @ x ~ b . Where 1) A is a matrix of MNIST digits images 2) x is a weight vector we wish to FIND 3) b is the classes vector we train with / predict (here the values would be 0/1 coordinate to 2 optional classes) . To acheive this I will implement Logistic Regression algorithm using Gradient descent . Boring imports . import numpy as np from numpy import linalg import struct from array import array from os.path import join import os import random import matplotlib.pyplot as plt . Boring setup - Load MNIST data . class MnistDataloader(object): def __init__(self, training_images_filepath,training_labels_filepath, test_images_filepath, test_labels_filepath): self.training_images_filepath = training_images_filepath self.training_labels_filepath = training_labels_filepath self.test_images_filepath = test_images_filepath self.test_labels_filepath = test_labels_filepath def read_images_labels(self, images_filepath, labels_filepath): labels = [] with open(labels_filepath, &#39;rb&#39;) as file: magic, size = struct.unpack(&quot;&gt;II&quot;, file.read(8)) if magic != 2049: raise ValueError(&#39;Magic number mismatch, expected 2049, got {}&#39;.format(magic)) labels = array(&quot;B&quot;, file.read()) with open(images_filepath, &#39;rb&#39;) as file: magic, size, rows, cols = struct.unpack(&quot;&gt;IIII&quot;, file.read(16)) if magic != 2051: raise ValueError(&#39;Magic number mismatch, expected 2051, got {}&#39;.format(magic)) image_data = array(&quot;B&quot;, file.read()) images = [] for i in range(size): images.append([0] * rows * cols) for i in range(size): img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols]) #img = img.reshape(28, 28) meanval = np.mean(img) stdval = np.std(img) img = (img - meanval) / (stdval + 0.1) images[i][:] = img return images, labels def load_data(self): x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath) x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath) return (x_train, y_train),(x_test, y_test) # # Set file paths based on added MNIST Datasets # cwd = os.getcwd() input_path = cwd + &quot;/../assets/&quot; training_images_filepath = join(input_path, &#39;train-images-idx3-ubyte&#39;) training_labels_filepath = join(input_path, &#39;train-labels-idx1-ubyte&#39;) test_images_filepath = join(input_path, &#39;t10k-images-idx3-ubyte&#39;) test_labels_filepath = join(input_path, &#39;t10k-labels-idx1-ubyte&#39;) # # Load MINST dataset # mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath) (x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data() . # Helper function to show a list of images with their relating titles # def show_images(images, title_texts): cols = 5 rows = int(len(images)/cols) + 1 plt.figure(figsize=(30,20)) index = 1 for x in zip(images, title_texts): image = x[0] title_text = x[1] plt.subplot(rows, cols, index) plt.imshow(image, cmap=plt.cm.gray) if (title_text != &#39;&#39;): plt.title(title_text, fontsize = 15); index += 1 plt.show() . Creating columns vectors of [1,0,0,1,0,0,...,0,1] indexes of label 8/9 , 1/0 . c1_8 = np.where(8 == np.array(y_train_89), 1 , 0) c1_8_test = np.where(8 == np.array(y_test_89), 1 , 0) c2_9 = np.where(9 == np.array(y_train_89), 1 , 0) c1_0 = np.where(0 == np.array(y_train_10), 1 , 0) c1_0_test = np.where(0 == np.array(y_test_10), 1 , 0) c2_1 = np.where(1 == np.array(y_train_10), 1 , 0) . Peek at our data . Let&#39;s see whether we&#39;ve filtered correclty the images . images_2_show = [] titles_2_show = [] sample_size = 20 for i in range(0, sample_size): r = random.randint(1, len(x_train_10)) images_2_show.append(np.array(x_train_10[r]).reshape(28,28)) titles_2_show.append(&#39;training image [&#39; + str(r) + &#39;] = &#39; + str(y_train_10[r])) show_images(images_2_show, titles_2_show) . images_2_show = [] titles_2_show = [] sample_size = 20 for i in range(0, sample_size): r = random.randint(1, len(x_train_89)) images_2_show.append(np.array(x_train_89[r]).reshape(28,28)) titles_2_show.append(&#39;training image [&#39; + str(r) + &#39;] = &#39; + str(y_train_89[r])) show_images(images_2_show, titles_2_show) . Sigmoid ; Sig-inverse ; Gradient ; Hessian . def sigmoid(x): return 1/(1 + np.exp(-x)) def siginv(y): return np.log(y/(1 - y)) def gradient(X,w,b): return (1/X.shape[1]) * X.T @ (sigmoid(X @ w) - b) def hessian(X,w): D = np.diag(sigmoid(X @ w) * (1-sigmoid(X @ w))) return (1/X.shape[1]) * X.T @ D @ X . THE target function . That is the cost function which we would like to minimize . def F(X,w,b): return (-1 / len(X)) * (b @ np.log(sigmoid(X @ w)) + (1-b) @ np.log(1 - sigmoid(X @ w))) . Gradient descent . That is a first-order iterative optimization algorithm for finding a local minimum. we would use (-1) * gradient for the direction of the algorithm, and armijo line search alpha for the step size we take each time. . # 0 &lt; c &lt; 1 def armijo_search_logistic(f,X,w_k,b,grad,d,maxIter = 1000,alpha0=1): alpha = alpha0 beta = 0.5 c = 10e-4 f_w_k = f(X,w_k,b) for _ in range(maxIter): X = np.array(X) if f(X,w_k + alpha * d,b) &lt;= f_w_k + c * alpha * np.dot(grad(X,w_k,b),d): return alpha else: alpha = beta * alpha def gradient_descent(F,X,w0,b,grad,max_iter): F_arr = [F(X, w0, b)] w = w0 for _ in range(max_iter): d = -1 * grad(X, w, b) alpha = armijo_search_logistic(F, X, w, b, grad, d, 100) w_next = w + alpha * d F_arr.append(F(X, w, b)) w = w_next return w , F_arr . Training our model . We run gradient descent on both 1/0 , 8/9 datasets for maximum of 100 iterations. . w_guess = np.ones(784) # starting with a random guess of weights optimal_w_89_gd, diff_arr_89 = gradient_descent(F, x_train_89, w_guess, c1_8, gradient, 100) optimal_w_10_gd, diff_arr_10 = gradient_descent(F, x_train_10, w_guess, c1_0, gradient, 100) . /var/folders/yq/mkgzhy8x5jz5z1dtjg0_4b5m0000gn/T/ipykernel_20277/2436934397.py:3: RuntimeWarning: divide by zero encountered in log return (-1 / len(X)) * (b @ np.log(sigmoid(X @ w)) + (1-b) @ np.log(1 - sigmoid(X @ w))) /var/folders/yq/mkgzhy8x5jz5z1dtjg0_4b5m0000gn/T/ipykernel_20277/2436934397.py:3: RuntimeWarning: invalid value encountered in matmul return (-1 / len(X)) * (b @ np.log(sigmoid(X @ w)) + (1-b) @ np.log(1 - sigmoid(X @ w))) /var/folders/yq/mkgzhy8x5jz5z1dtjg0_4b5m0000gn/T/ipykernel_20277/2472746357.py:2: RuntimeWarning: overflow encountered in exp return 1/(1 + np.exp(-x)) . RESULTS - 8/9 model accuracy + plot . We&#39;ve found the optimal weights vector, now lets test it on the TEST data which our model never saw. we set a threshold of 0.5 and for every given image X we test: . sigmoid(X@w) &gt; 0.5 ? &#39;class 1&#39; :&#39;class 0&#39; . c1 = 8 c2 = 9 sig_dig_8 = [] sig_dig_9 = [] b_predict = sigmoid(x_test_89 @ optimal_w_89_gd) b_predict_classify_89 = np.where(b_predict &gt; 0.5 ,1 ,0) model_accuracy = 100 * (c1_8_test == b_predict_classify_89).sum() / len(c1_8_test) print(&quot;Detect 8/9 model accuracy: &quot;, &quot;{:.4f} %&quot;.format(model_accuracy)) for predict,real in zip(b_predict, y_test_89): if real == c1: sig_dig_8.append(predict) elif real == c2: sig_dig_9.append(predict) x = np.linspace(-10, 10, 100) plt.plot(x, sigmoid(x)) plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;Sigmoid(X)&quot;) plt.scatter([siginv(x) for x in sig_dig_8], sig_dig_8, color = &#39;red&#39;,label=&quot;Digit &#39;8&#39;&quot;,s=1) plt.scatter([siginv(x) for x in sig_dig_9], sig_dig_9, color = &#39;blue&#39;,label=&quot;Digit &#39;9&#39;&quot;,s=1) plt.legend() plt.show() print(&quot;Digit 8 mean: &quot;,&quot;{:.4f}&quot;.format(np.array(sig_dig_8).mean())) print(&quot;Digit 9 mean: &quot;,&quot;{:.4f}&quot;.format(np.array(sig_dig_9).mean())) . Detect 8/9 model accuracy: 98.1846 % . Digit 8 mean: 0.9708 Digit 9 mean: 0.0355 . RESULTS - 1/0 model accuracy + plot . sig_dig_1 = [] sig_dig_0 = [] c1 = 1 c2 = 0 b_predict = sigmoid(x_test_10 @ optimal_w_10_gd) b_predict_classify_10 = np.where(b_predict &gt; 0.5 ,1 ,0) model_accuracy = 100 * (c1_0_test == b_predict_classify_10).sum() / len(c1_0_test) print(&quot;Detect 8/9 model accuracy: &quot;, &quot;{:.4f} %&quot;.format(model_accuracy)) for predict,real in zip(b_predict, y_test_10): if real == c1: sig_dig_1.append(predict) elif real == c2: sig_dig_0.append(predict) x = np.linspace(-30, 30, 100) plt.plot(x, sigmoid(x)) plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;Sigmoid(X)&quot;) plt.scatter([siginv(x) for x in sig_dig_1], sig_dig_1, color = &#39;red&#39;,label=&quot;Digit &#39;1&#39;&quot;,s=1) plt.scatter([siginv(x) for x in sig_dig_0], sig_dig_0, color = &#39;blue&#39;,label=&quot;Digit &#39;0&#39;&quot;,s=1) plt.legend() plt.show() print(&quot;Digit 1 mean: &quot;,&quot;{:.4f}&quot;.format(np.array(sig_dig_1).mean())) print(&quot;Digit 0 mean: &quot;,&quot;{:.4f}&quot;.format(np.array(sig_dig_0).mean())) . Detect 8/9 model accuracy: 99.9527 % . Digit 1 mean: 0.0010 Digit 0 mean: 0.9990 . FINAL THOUGHTS . We can conclude, using the weight vector we found, we can easliy detect if a given image X is class 0/1 by multiplying by w, (X @ w) and performiming sigmoid function on the result. then, comparing to the threshold . sigmoid(X@w) &gt; 0.5 ? &#39;class 1&#39; :&#39;class 0&#39; .",
            "url": "https://orbitoly.github.io/Machine-Learning-Notebook-Or-Virt/ml/logistic%20regression/2022/06/17/implementing-logistic-regression.html",
            "relUrl": "/ml/logistic%20regression/2022/06/17/implementing-logistic-regression.html",
            "date": " • Jun 17, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://orbitoly.github.io/Machine-Learning-Notebook-Or-Virt/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://orbitoly.github.io/Machine-Learning-Notebook-Or-Virt/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://orbitoly.github.io/Machine-Learning-Notebook-Or-Virt/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://orbitoly.github.io/Machine-Learning-Notebook-Or-Virt/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}